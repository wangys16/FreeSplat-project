<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="google-site-verification" content="fRDPSSrup3me5GYUp-L7tI2HI00CV-3Guyv5sRL8_no" />
  <meta name="description"
        content="FreeSplat: Generalizable 3D Gaussian Splatting Towards Free-View Synthesis of Indoor Scenes.">
  <meta name="keywords" content="FreeSplat, freesplat">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>FreeSplat: Generalizable 3D Gaussian Splatting Towards Free-View Synthesis of Indoor Scenes</title>

  <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-4JJ9LR7EM2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-4JJ9LR7EM2');
</script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
<!--  <link rel="icon" href="./static/images/favicon.svg">-->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!--<nav class="navbar" role="navigation" aria-label="main navigation">-->
<!--  <div class="navbar-brand">-->
<!--    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">-->
<!--      <span aria-hidden="true"></span>-->
<!--      <span aria-hidden="true"></span>-->
<!--      <span aria-hidden="true"></span>-->
<!--    </a>-->
<!--  </div>-->
<!--  <div class="navbar-menu">-->
<!--    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">-->
<!--      <a class="navbar-item" href="https://keunhong.com">-->
<!--      <span class="icon">-->
<!--          <i class="fas fa-home"></i>-->
<!--      </span>-->
<!--      </a>-->

<!--      <div class="navbar-item has-dropdown is-hoverable">-->
<!--        <a class="navbar-link">-->
<!--          More Research-->
<!--        </a>-->
<!--        <div class="navbar-dropdown">-->
<!--          <a class="navbar-item" href="https://hypernerf.github.io">-->
<!--            HyperNeRF-->
<!--          </a>-->
<!--          <a class="navbar-item" href="https://nerfies.github.io">-->
<!--            Nerfies-->
<!--          </a>-->
<!--          <a class="navbar-item" href="https://latentfusion.github.io">-->
<!--            LatentFusion-->
<!--          </a>-->
<!--          <a class="navbar-item" href="https://photoshape.github.io">-->
<!--            PhotoShape-->
<!--          </a>-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->

<!--  </div>-->
<!--</nav>-->


<section class="hero">
  <div class="hero-body">
    <div class="container ">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">SurfelNeRF: Neural Surfel Radiance Fields for Online Photorealistic Reconstruction of Indoor Scenes</h1>
          <h2>CVPR 2023</h2>
          <p class="abstract">Large scale online photorealistic reconstruction of indoor scenes. </p>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=uRCc-McAAAAJ&hl=zh-TW">Yiming Gao</a>,</span>
            <span class="author-block">
              <a href="https://yanpei.me/">Yan-Pei Cao</a>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=4oXBp9UAAAAJ&hl=en-us">Ying Shan</a>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">ARC Lab, Tencent PCG</span>
<!--            <span class="author-block"><sup>2</sup>Google Research</span>-->
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2304.08971"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2304.08971"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
<!--              <span class="link-block">-->
<!--                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="fab fa-youtube"></i>-->
<!--                  </span>-->
<!--                  <span>Video</span>-->
<!--                </a>-->
<!--              </span>-->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/TencentARC/SurfelNeRF"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
<!--              <span class="link-block">-->
<!--                <a href="https://github.com/google/nerfies/releases/tag/0.1"-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="far fa-images"></i>-->
<!--                  </span>-->
<!--                  <span>Data</span>-->
<!--                  </a>-->
<!--              </span>    -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!--<section class="hero is-small">-->
<!--  <div class="hero-body">-->
<!--    <div class="container">-->
<!--      <div id="results-carousel" class="carousel results-carousel">-->
<!--        <div class="item item-t0" align="center">-->
<!--          &lt;!&ndash; <video poster="" id="bird0" autoplay controls muted loop height="100%">-->
<!--            <source src="static/videos/bird0_5_14.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video> &ndash;&gt;-->
<!--          <img src="static/images/teaser.png" width="40%" alt="overview_image">-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->
<!--  </div>-->
<!--   	<div align="center">-->
<!--		&lt;!&ndash; *Results above are generated using our single pretrained model without per-scene optimization &ndash;&gt;-->
<!--	</div>-->
<!--</section>-->


<section class="section">
  <div align="center" >
    <img style="height: auto; width: 40%; object-fit: contain" src="static/images/teaser.png" alt="overview_image">
  </div>
  <div class="container">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Online reconstructing and rendering of large-scale indoor scenes is a long-standing challenge. SLAM-based methods can  reconstruct 3D scene geometry progressively in real time but can not render photorealistic results.
            While NeRF-based methods produce promising novel view synthesis results, their long offline optimization time and lack of geometric constraints pose challenges to efficiently handling online input.
            Inspired by the complementary advantages of classical 3D reconstruction and NeRF, we thus investigate marrying explicit geometric representation with NeRF rendering to achieve efficient online reconstruction and high-quality rendering.
            We introduce SurfelNeRF, a variant of neural radiance field which employs a flexible and scalable neural surfel representation to store geometric attributes and extracted appearance features from input images.
            We further extend the conventional surfel-based fusion scheme to progressively integrate incoming input frames into the reconstructed global neural scene representation.
            In addition, we propose a highly-efficient differentiable rasterization scheme for rendering neural surfel radiance fields, which helps SurfelNeRF achieve 10&times speedups in training and inference time, respectively.
            Experimental results show that our method achieves the state-of-the-art 23.82 PSNR and 29.58 PSNR on ScanNet in feedforward inference and per-scene optimization settings, respectively.
          </p>
        </div>
      </div>
    </div>
  </div>
<!---->
  <div class="container" style="margin-top:50px;">
  <div class="columns is-centered has-text-centered">
  <div class="column is-four-fifths">
  <h2 class="title is-3">Pipeline</h2>
  <div class="content has-text-justified">
  <div align="center" style="margin-top:40px;">
    <img style="height: auto; width: 75%; object-fit: contain" src="static/images/overview.png" alt="overview_image">
  </div>
    <p>
    Overview of our SurfelNeRF. Given an online input stream of image sequences, we first reconstruct a surfel representation associated with neural features to build a local neural surfel radiance field for each input keyframe. Then the neural surfel radiance field integration is used to fuse the input local neural surfel radiance field into the global neural surfel radiance field by updating both surfel position and features. More specifically, input local neural surfels associated with global surfels are fused to global surfels with corresponding global ones, and remaining local surfels without corresponding ones are added to the global model. Furthermore, the novel views can be rendered from updated global surfels via our efficient rasterization-guided render. Our proposed rasterization-guided renderer renders color only on the intersection points of ray and surfels, which is faster than volume rendering.
    </p>
    <!--  -->
  <div align="center" style="margin-top:40px;">
    <img style="height: auto; width: 75%; object-fit: contain" src="static/images/table_in_surfelnerf.png" alt="feat_table">
  </div>
    <div align="center">
      <p>Comparison of representation and features with existing methods.</p>
    </div>
  </div>
  </div>
  </div>
  </div>

<!--  -->
  <section class="section">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 align="center" class="title is-2">Results</h2>

        <!-- ScanNet Main -->
        <h3 align="center" style="margin-top:80px;" class="title is-4">ScanNet</h3>
        <div class="content has-text-justified">
        </div>
        <div class="content has-text-centered">
          <video id="replay-video" controls="" muted="" width="65%">
            <source src="static/videos/SurfelNeRF_video.mp4" type="video/mp4">
          </video>
        </div>
        <!-- ScanNet Main -->

      </div>
    </div>
    <!--/ Animation. -->
  </div>
</section>

</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{gao2023surfelnerf,
  author    = {Gao, Yiming and Cao, Yan-Pei and Shan, Ying },
  title     = {SurfelNeRF: Neural Surfel Radiance Fields for Online Photorealistic Reconstruction of Indoor Scenes},
  journal   = {CVPR},
  year      = {2023},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div align="center" class="content has-text-centered">
      <a class="icon-link"
         href="https://arxiv.org/abs/2304.08971">
        <i class="fas fa-file-pdf"></i>
      </a>
<!--      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>-->
<!--        <i class="fab fa-github"></i>-->
<!--      </a>-->
    </div>
    <div class="container" align="center">
      <div class="column is-centered">
        <div class="content">
          <p>
            This website is borrowed from <a href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
